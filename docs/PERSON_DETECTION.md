# Toronto Gait Output File Formats and Person Selection

## Table of Contents

1. [Overview](#overview)
2. [File Format Details](#1-file-format-details)
   - [gait.csv](#gaitcsv)
   - [gait.json](#gaitjson)
3. [How Are People Detected and Represented?](#2-how-are-people-detected-and-represented)
   - [Detection and Tracking](#detection-and-tracking)
   - [Representation in Files](#representation-in-files)
4. [How Is the Main Person (Older Adult) Determined?](#3-how-is-the-main-person-older-adult-determined)
   - [Current Behavior](#current-behavior)
   - [Example Issue](#example-issue)
5. [Recommendations: Selecting the Most Salient Person](#4-recommendations-selecting-the-most-salient-person)
   - [Why Selection Is Needed](#why-selection-is-needed)
   - [OpenPose Person Detection Reliability](#openpose-person-detection-reliability)
   - [How to Select the Main Person](#how-to-select-the-main-person)
6. [Error Diagnosis and Fixes](#5-error-diagnosis-and-fixes)
   - [Potential Errors](#potential-errors)
   - [How to Fix](#how-to-fix)
7. [Summary Table](#6-summary-table)
8. [Recommendations for Codebase](#7-recommendations-for-codebase)
9. [References](#8-references)
10. [Appendix: Example Implementation](#appendix-example-implementation)

---

## Overview

The `gait.csv` and `gait.json` files are generated by running the Toronto dataset videos through the pose detection pipeline using the provided PowerShell scripts (`run-openpose-batch.ps1`, `run-openpose.ps1`), which invoke the logic in `cli/detect.py`. These files contain pose and gait analysis data for people detected in the videos.

---

## 1. File Format Details

### gait.csv

- **Structure**: Each row represents a single frame for a single person (by default, the first detected person in each frame).
- **Columns**:
  - `time`: Timestamp of the frame (in seconds).
  - For each joint (e.g., `Nose`, `LEye`, `REye`, ...): three columns per joint:
    - `<joint>_x`: X coordinate
    - `<joint>_y`: Y coordinate
    - `<joint>_conf`: Confidence score (0-1)
- **Person Representation**: Only one person per frame is included (by default, the first detected person).

### gait.json

- **Structure**: Contains metadata, a summary, and a `gait_analysis` array with per-person gait metrics and raw data.
- **Sections**:
  - `metadata`: Information about the input, processing parameters, and video.
  - `summary`: 
    - `total_people_analyzed`: Number of people for whom gait metrics were computed (see below for caveats).
    - `total_frames_processed`: Total frames used in analysis.
    - `analysis_duration`: Total duration analyzed.
  - `gait_analysis`: Array of objects, one per detected person, each with:
    - `person_id`
    - `total_frames`
    - `duration_seconds`
    - `gait_metrics` (stride length, step frequency, asymmetry)
    - `raw_data` (timestamps, joint trajectories)

---

## 2. How Are People Detected and Represented?

### Detection and Tracking

- **Detection**: Each frame is processed by a pose detector (OpenPose, MediaPipe, etc.), which outputs a list of detected people, each with keypoints and a bounding box.
- **Tracking**: The `PersonTracker` class assigns a consistent `person_id` to each detected person across frames using bounding box IoU matching.
- **Order of Detection**: The order is determined by the detector's output, and the tracker maintains the mapping across frames.

### Representation in Files

- **CSV**: Only the first detected/tracked person per frame is written to the CSV (see `save_toronto_csv_format`).
- **JSON**: All tracked people with at least 10 frames of data are included in the `gait_analysis` array.

---

## 3. How Is the Main Person (Older Adult) Determined?

### Current Behavior

- **No Explicit Selection**: The code does **not** explicitly select the "main" or "most salient" person (e.g., the older adult). All tracked people with sufficient data are included in the JSON. The CSV always uses the first detected person per frame, which may not be consistent across frames if tracking fails or IDs are reassigned.
- **Potential Issues**:
  - If multiple people are present, all may be included in the JSON, leading to `total_people_analyzed` > 1.
  - If tracking is imperfect, a single person may be split into multiple `person_id`s, inflating the count.
  - In rare cases, spurious detections or tracking errors can cause the summary to report more people than are visually present.

#### Example Issue

> In `04/gait.json`, there are only 2 people in the video, but the summary says `total_people_analyzed` is 9.

- This is likely due to tracking fragmentation (the same person being assigned multiple IDs due to missed detections or occlusions), or spurious detections.

---

## 4. Recommendations: Selecting the Most Salient Person

### Why Selection Is Needed

For gait analysis, we typically want to analyze only the main subject (e.g., the older adult walking), not bystanders or fragmented tracks.

### OpenPose Person Detection Reliability

**Can we rely on OpenPose's person detection to identify the dominant person walking?**

**Answer: No, not reliably.**

OpenPose's person detection has the following characteristics:

1. **Detection Order**: OpenPose returns detected people in the order they appear in its internal detection array, which is **not guaranteed to correspond to dominance or importance**.

2. **No Built-in Dominance Logic**: OpenPose itself has no mechanism to identify which person is the "main subject" or "dominant person" in a walking sequence.

3. **Frame-by-Frame Inconsistency**: The order of detected people can vary between frames, making it unreliable for identifying the consistent main subject.

4. **All People Processed**: The current implementation processes all detected people without any filtering or selection logic.

**Implications for Gait Analysis:**
- The first person detected in each frame may not be the main subject
- Multiple people in the video will all be processed and included in the output
- This can lead to mixed gait data from different people
- The `total_people_analyzed` count may not reflect the actual number of distinct people in the video

### How to Select the Main Person

#### **A. Heuristic Approaches (Recommended for Most Cases)**

- **Longest Track**: Select the `person_id` with the most frames (`total_frames`).
- **Most Central**: Select the person whose bounding box center is closest to the center of the frame on average.
- **Largest Bounding Box**: Select the person with the largest average bounding box area (often the closest/largest person).
- **Manual Selection**: Allow the user to specify the `person_id` to use (e.g., via a CLI argument).

#### **B. Implementation Plan**

**To implement "select only the most salient person" in the JSON and CSV outputs:**

1. **After tracking and before saving results:**
   - Compute a score for each `person_id` (e.g., by `total_frames`).
   - Select the `person_id` with the highest score.
2. **Filter**:
   - For JSON: Only include this `person_id` in the `gait_analysis` array.
   - For CSV: Only write rows for this `person_id` (instead of the first detected per frame).

**Example Code Snippet:**

```python
# After building gait_data (person_id -> frames)
# Select the person with the most frames (longest track)
main_person_id = max(gait_data, key=lambda pid: len(gait_data[pid]))

# Or select the most central person
from cli.person_selection import create_person_selector
selector = create_person_selector(heuristic="most_central", min_frames=10)
main_person_id = selector.select_main_person(gait_data)

# When building gait_analysis, only include main_person_id
for person_id, person_data in gait_data.items():
    if person_id != main_person_id:
        continue
    # ... existing gait analysis logic ...
```

**For CSV:**
- When grouping poses by frame, select the pose with `person_id == main_person_id`.

---

## 5. Error Diagnosis and Fixes

### Potential Errors

- **Tracking Fragmentation**: If the same person is assigned multiple IDs, the analysis will be split, and `total_people_analyzed` will be inflated.
- **Spurious Detections**: False positives or short-lived tracks may be included if not filtered out (the code already skips tracks with <10 frames, but this may not be enough).

### How to Fix

- **Improve Tracking**: Tune the IoU threshold or use more sophisticated tracking (e.g., appearance-based).
- **Post-Processing**: Merge tracks that are likely to belong to the same person (e.g., based on spatial/temporal proximity).
- **Salient Person Selection**: As above, always select the main person for output.

---

## 6. Summary Table

| File         | People Included         | How Person is Chosen         | Notes                                      |
|--------------|------------------------|------------------------------|--------------------------------------------|
| gait.csv     | 1 per frame            | First detected (not robust)  | May not be consistent across frames        |
| gait.json    | All with â‰¥10 frames    | All tracked                  | May include bystanders, fragmented tracks  |

---

## 7. Recommendations for Codebase

- **Add a main person selection step** before output.
- **Document the selection logic** in the code and output files.
- **Optionally, expose a CLI argument** to allow user override.

---

## 8. References

- `cli/detect.py`: Person tracking (`PersonTracker`), output formatting (`save_toronto_gait_format`, `save_toronto_csv_format`)
- Toronto Gait Dataset documentation

---

# Appendix: Example Implementation

```python
# Select main person by longest track
main_person_id = max(gait_data, key=lambda pid: len(gait_data[pid]))

# Filter gait_analysis to only include main_person_id
gait_analysis = []
for person_id, person_data in gait_data.items():
    if person_id != main_person_id:
        continue
    # ... existing gait analysis logic ...
```

---

**If you would like a code patch to implement this, please specify your preferred selection heuristic (e.g., longest track, most central, largest bounding box, etc.).**

## Implementation Status

The "most central" heuristic has been implemented and is available in the codebase:

- **CLI Option**: `--person-selection most_central`
- **Implementation**: `cli/person_selection.py` - `MostCentralHeuristic` class
- **Documentation**: `docs/MOST_CENTRAL_HEURISTIC.md`
- **Tests**: `tests/test_person_selection.py`
- **Script**: `scripts/apply_most_central_to_existing_outputs.py`

The heuristic is fully integrated with both JSON and CSV output formats and includes comprehensive error handling and logging. 